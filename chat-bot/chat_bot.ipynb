{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'up': 1,\n",
       " 'bedroom': 2,\n",
       " 'discarded': 3,\n",
       " 'sandra': 4,\n",
       " 'journeyed': 5,\n",
       " '?': 6,\n",
       " 'hallway': 7,\n",
       " 'picked': 8,\n",
       " 'mary': 9,\n",
       " 'went': 10,\n",
       " 'put': 11,\n",
       " 'bathroom': 12,\n",
       " 'moved': 13,\n",
       " 'yes': 14,\n",
       " 'dropped': 15,\n",
       " 'there': 16,\n",
       " 'daniel': 17,\n",
       " 'football': 18,\n",
       " 'to': 19,\n",
       " 'no': 20,\n",
       " 'the': 21,\n",
       " 'milk': 22,\n",
       " 'office': 23,\n",
       " 'kitchen': 24,\n",
       " 'is': 25,\n",
       " 'in': 26,\n",
       " 'john': 27,\n",
       " 'back': 28,\n",
       " 'took': 29,\n",
       " 'garden': 30,\n",
       " 'travelled': 31,\n",
       " 'left': 32,\n",
       " 'got': 33,\n",
       " 'grabbed': 34,\n",
       " 'apple': 35,\n",
       " 'down': 36,\n",
       " '.': 37}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 21,  2, 37],\n",
       "       [ 0,  0,  0, ..., 21, 30, 37],\n",
       "       [ 0,  0,  0, ..., 21, 30, 37],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 21, 35, 37],\n",
       "       [ 0,  0,  0, ..., 21, 30, 37],\n",
       "       [ 0,  0,  0, ..., 35, 16, 37]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25, 27, 26, 21, 24,  6],\n",
       "       [25, 27, 26, 21, 24,  6],\n",
       "       [25, 27, 26, 21, 30,  6],\n",
       "       ...,\n",
       "       [25,  9, 26, 21,  2,  6],\n",
       "       [25,  4, 26, 21, 30,  6],\n",
       "       [25,  9, 26, 21, 30,  6]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0., 503.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 64)     2432        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 7s 14ms/step - loss: 0.9037 - accuracy: 0.4914 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.7018 - accuracy: 0.5074 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6953 - accuracy: 0.4993 - val_loss: 0.6942 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6957 - accuracy: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6946 - accuracy: 0.4976 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.4968 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6951 - accuracy: 0.4946 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6947 - accuracy: 0.4903 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6948 - accuracy: 0.4876 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.6938 - accuracy: 0.5058 - val_loss: 0.6945 - val_accuracy: 0.4520\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6924 - accuracy: 0.5126 - val_loss: 0.6971 - val_accuracy: 0.4970\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6865 - accuracy: 0.5365 - val_loss: 0.6862 - val_accuracy: 0.5440\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.6717 - accuracy: 0.5716 - val_loss: 0.6567 - val_accuracy: 0.6400\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6458 - accuracy: 0.6314 - val_loss: 0.6177 - val_accuracy: 0.6650\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6229 - accuracy: 0.6553 - val_loss: 0.5983 - val_accuracy: 0.6820\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.5976 - accuracy: 0.6843 - val_loss: 0.5616 - val_accuracy: 0.7230\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5656 - accuracy: 0.7073 - val_loss: 0.5525 - val_accuracy: 0.7230\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.5389 - accuracy: 0.7328 - val_loss: 0.4828 - val_accuracy: 0.7770\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.5075 - accuracy: 0.7582 - val_loss: 0.4658 - val_accuracy: 0.7880\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4906 - accuracy: 0.7695 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4794 - accuracy: 0.7794 - val_loss: 0.4382 - val_accuracy: 0.8090\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4643 - accuracy: 0.7878 - val_loss: 0.4282 - val_accuracy: 0.8140\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4549 - accuracy: 0.7940 - val_loss: 0.4351 - val_accuracy: 0.8040\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4430 - accuracy: 0.7988 - val_loss: 0.4125 - val_accuracy: 0.8040\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4258 - accuracy: 0.8116 - val_loss: 0.4183 - val_accuracy: 0.8090\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4204 - accuracy: 0.8158 - val_loss: 0.4099 - val_accuracy: 0.8130\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4048 - accuracy: 0.8195 - val_loss: 0.3984 - val_accuracy: 0.8190\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4035 - accuracy: 0.8235 - val_loss: 0.4161 - val_accuracy: 0.8090\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3963 - accuracy: 0.8272 - val_loss: 0.3903 - val_accuracy: 0.8230\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3908 - accuracy: 0.8310 - val_loss: 0.3952 - val_accuracy: 0.8260\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3869 - accuracy: 0.8327 - val_loss: 0.3841 - val_accuracy: 0.8240\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3850 - accuracy: 0.8285 - val_loss: 0.3959 - val_accuracy: 0.8100\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3771 - accuracy: 0.8365 - val_loss: 0.3799 - val_accuracy: 0.8200\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3694 - accuracy: 0.8417 - val_loss: 0.3788 - val_accuracy: 0.8160\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3667 - accuracy: 0.8407 - val_loss: 0.3800 - val_accuracy: 0.8210\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3635 - accuracy: 0.8437 - val_loss: 0.3805 - val_accuracy: 0.8210\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3552 - accuracy: 0.8472 - val_loss: 0.3926 - val_accuracy: 0.8170\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3596 - accuracy: 0.8441 - val_loss: 0.3737 - val_accuracy: 0.8270\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.3420 - accuracy: 0.8536 - val_loss: 0.3798 - val_accuracy: 0.8260\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3482 - accuracy: 0.8494 - val_loss: 0.3823 - val_accuracy: 0.8230\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3470 - accuracy: 0.8537 - val_loss: 0.3756 - val_accuracy: 0.8360\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3452 - accuracy: 0.8513 - val_loss: 0.3701 - val_accuracy: 0.8300\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3368 - accuracy: 0.8526 - val_loss: 0.3787 - val_accuracy: 0.8300\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3385 - accuracy: 0.8590 - val_loss: 0.3658 - val_accuracy: 0.8270\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3293 - accuracy: 0.8587 - val_loss: 0.3714 - val_accuracy: 0.8210\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3307 - accuracy: 0.8567 - val_loss: 0.3795 - val_accuracy: 0.8270\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3265 - accuracy: 0.8583 - val_loss: 0.3678 - val_accuracy: 0.8300\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3194 - accuracy: 0.8625 - val_loss: 0.4005 - val_accuracy: 0.8020\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3254 - accuracy: 0.8582 - val_loss: 0.3542 - val_accuracy: 0.8310\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3228 - accuracy: 0.8625 - val_loss: 0.3676 - val_accuracy: 0.8330\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3200 - accuracy: 0.8679 - val_loss: 0.3624 - val_accuracy: 0.8340\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3107 - accuracy: 0.8683 - val_loss: 0.3697 - val_accuracy: 0.8330\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3124 - accuracy: 0.8654 - val_loss: 0.3906 - val_accuracy: 0.8300\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3092 - accuracy: 0.8681 - val_loss: 0.3655 - val_accuracy: 0.8190\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.3620 - val_accuracy: 0.8270\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3033 - accuracy: 0.8711 - val_loss: 0.3725 - val_accuracy: 0.8310\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3012 - accuracy: 0.8717 - val_loss: 0.3803 - val_accuracy: 0.8170\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3049 - accuracy: 0.8679 - val_loss: 0.3866 - val_accuracy: 0.8320\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3023 - accuracy: 0.8716 - val_loss: 0.3893 - val_accuracy: 0.8360\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2985 - accuracy: 0.8717 - val_loss: 0.3733 - val_accuracy: 0.8280\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3001 - accuracy: 0.8701 - val_loss: 0.3812 - val_accuracy: 0.8330\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2916 - accuracy: 0.8779 - val_loss: 0.3745 - val_accuracy: 0.8220\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2982 - accuracy: 0.8727 - val_loss: 0.3752 - val_accuracy: 0.8290\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2947 - accuracy: 0.8744 - val_loss: 0.3658 - val_accuracy: 0.8340\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2850 - accuracy: 0.8775 - val_loss: 0.3668 - val_accuracy: 0.8320\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2863 - accuracy: 0.8782 - val_loss: 0.3697 - val_accuracy: 0.8210\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2853 - accuracy: 0.8768 - val_loss: 0.3757 - val_accuracy: 0.8350\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2842 - accuracy: 0.8797 - val_loss: 0.3766 - val_accuracy: 0.8340\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2865 - accuracy: 0.8811 - val_loss: 0.3828 - val_accuracy: 0.8260\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2822 - accuracy: 0.8768 - val_loss: 0.3836 - val_accuracy: 0.8240\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2807 - accuracy: 0.8824 - val_loss: 0.3907 - val_accuracy: 0.8280\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2769 - accuracy: 0.8782 - val_loss: 0.4123 - val_accuracy: 0.8190\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2752 - accuracy: 0.8824 - val_loss: 0.3843 - val_accuracy: 0.8330\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2716 - accuracy: 0.8820 - val_loss: 0.3894 - val_accuracy: 0.8150\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2767 - accuracy: 0.8819 - val_loss: 0.3920 - val_accuracy: 0.8290\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2686 - accuracy: 0.8865 - val_loss: 0.3919 - val_accuracy: 0.8340\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2686 - accuracy: 0.8848 - val_loss: 0.3883 - val_accuracy: 0.8340\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2689 - accuracy: 0.8823 - val_loss: 0.3998 - val_accuracy: 0.8350\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2653 - accuracy: 0.8840 - val_loss: 0.4107 - val_accuracy: 0.8370\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2620 - accuracy: 0.8891 - val_loss: 0.4094 - val_accuracy: 0.8330\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2715 - accuracy: 0.8842 - val_loss: 0.4156 - val_accuracy: 0.8130\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2574 - accuracy: 0.8900 - val_loss: 0.4115 - val_accuracy: 0.8320\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2571 - accuracy: 0.8891 - val_loss: 0.3995 - val_accuracy: 0.8200\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2621 - accuracy: 0.8881 - val_loss: 0.4092 - val_accuracy: 0.8370\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2541 - accuracy: 0.8926 - val_loss: 0.4282 - val_accuracy: 0.8290\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2543 - accuracy: 0.8929 - val_loss: 0.4294 - val_accuracy: 0.8240\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2545 - accuracy: 0.8866 - val_loss: 0.4078 - val_accuracy: 0.8330\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2521 - accuracy: 0.8920 - val_loss: 0.4221 - val_accuracy: 0.8360\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2510 - accuracy: 0.8927 - val_loss: 0.4266 - val_accuracy: 0.8190\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2509 - accuracy: 0.8939 - val_loss: 0.4065 - val_accuracy: 0.8250\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2545 - accuracy: 0.8933 - val_loss: 0.4045 - val_accuracy: 0.8330\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2494 - accuracy: 0.8942 - val_loss: 0.4229 - val_accuracy: 0.8320\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2444 - accuracy: 0.8963 - val_loss: 0.4340 - val_accuracy: 0.8230\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2463 - accuracy: 0.8971 - val_loss: 0.4798 - val_accuracy: 0.8130\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2421 - accuracy: 0.9005 - val_loss: 0.4337 - val_accuracy: 0.8370\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2424 - accuracy: 0.8992 - val_loss: 0.4269 - val_accuracy: 0.8360\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2430 - accuracy: 0.8989 - val_loss: 0.4085 - val_accuracy: 0.8380\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2377 - accuracy: 0.9024 - val_loss: 0.4223 - val_accuracy: 0.8240\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2369 - accuracy: 0.8999 - val_loss: 0.4369 - val_accuracy: 0.8310\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2352 - accuracy: 0.9009 - val_loss: 0.4446 - val_accuracy: 0.8230\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2356 - accuracy: 0.9012 - val_loss: 0.4337 - val_accuracy: 0.8260\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2350 - accuracy: 0.9027 - val_loss: 0.4349 - val_accuracy: 0.8250\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2270 - accuracy: 0.9075 - val_loss: 0.4352 - val_accuracy: 0.8210\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2320 - accuracy: 0.9038 - val_loss: 0.4889 - val_accuracy: 0.8330\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2297 - accuracy: 0.9039 - val_loss: 0.4688 - val_accuracy: 0.8260\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2277 - accuracy: 0.9062 - val_loss: 0.4735 - val_accuracy: 0.8290\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2217 - accuracy: 0.9082 - val_loss: 0.4652 - val_accuracy: 0.8180\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2295 - accuracy: 0.9037 - val_loss: 0.4737 - val_accuracy: 0.8220\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2310 - accuracy: 0.9045 - val_loss: 0.4799 - val_accuracy: 0.8260\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2194 - accuracy: 0.9110 - val_loss: 0.4976 - val_accuracy: 0.8160\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2190 - accuracy: 0.9100 - val_loss: 0.4789 - val_accuracy: 0.8180\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2193 - accuracy: 0.9107 - val_loss: 0.4943 - val_accuracy: 0.8250\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2188 - accuracy: 0.9079 - val_loss: 0.4829 - val_accuracy: 0.8340\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2227 - accuracy: 0.9066 - val_loss: 0.4878 - val_accuracy: 0.8200\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2134 - accuracy: 0.9086 - val_loss: 0.4823 - val_accuracy: 0.8310\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2179 - accuracy: 0.9099 - val_loss: 0.5029 - val_accuracy: 0.8270\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2081 - accuracy: 0.9131 - val_loss: 0.5268 - val_accuracy: 0.8240\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2147 - accuracy: 0.9107 - val_loss: 0.4991 - val_accuracy: 0.8340\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2142 - accuracy: 0.9099 - val_loss: 0.4887 - val_accuracy: 0.8340\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2078 - accuracy: 0.9143 - val_loss: 0.4651 - val_accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### PlottingTraining History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating onTest Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99999905\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
